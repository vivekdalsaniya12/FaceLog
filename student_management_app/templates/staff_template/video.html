<!DOCTYPE html>
<html>

<head>
    <meta charset="UTF-8">
    <title>Open Camera</title>
    <style>
        /* Position close and change camera buttons at the bottom center */
        #closeBtn,
        #changeCameraBtn {
            position: fixed;
            bottom: 20px;
            font-size: 16px;
            padding: 10px 20px;
        }

        #closeBtn {
            left: 50%;
            transform: translateX(-120%);
            background-color: rgb(233, 68, 68);
        }

        #changeCameraBtn {
            left: 50%;
            transform: translateX(20%);
        }

        /* Position speed control buttons at the top-right */
        #increaseSpeedBtn,
        #decreaseSpeedBtn {
            position: fixed;
            top: 20px;
            right: 20px;
            font-size: 20px;
            padding: 10px;
            width: 40px;
            height: 40px;
            display: flex;
            align-items: center;
            justify-content: center;
            border-radius: 50%;
        }

        #decreaseSpeedBtn {
            right: 70px;
        }
    </style>
</head>

<body>
    <!-- Fullscreen canvas for displaying processed frames -->
    <canvas id="videoCanvas"></canvas>
    <!-- Buttons for closing or changing camera -->
    <button id="closeBtn">Close Camera</button>
    <button id="changeCameraBtn">Change Camera</button>
    <!-- Buttons to control frame sending speed -->
    <button id="increaseSpeedBtn">+</button>
    <button id="decreaseSpeedBtn">-</button>
    <!-- Hidden video element to capture stream -->
    <video id="video" autoplay playsinline style="display: none;"></video>

    <script>
        const video = document.getElementById('video');
        const outputCanvas = document.getElementById('videoCanvas');
        const outputContext = outputCanvas.getContext('2d');
        const closeBtn = document.getElementById('closeBtn');
        const changeCameraBtn = document.getElementById('changeCameraBtn');
        const increaseSpeedBtn = document.getElementById('increaseSpeedBtn');
        const decreaseSpeedBtn = document.getElementById('decreaseSpeedBtn');
        const subjectData = "{{ subject_id }}";  // Render these on your template
        const sessionYearData = "{{ session_year }}";

        let currentFacingMode = 'user';  // 'user' for front, 'environment' for back
        let stream = null;
        let capturing = false;

        // Offscreen canvas for capturing frames (lower resolution for speed)
        const captureCanvas = document.createElement('canvas');
        const captureContext = captureCanvas.getContext('2d');

        // Frame queue to buffer incoming frames from the server.
        let frameQueue = [];
        let isDisplaying = false;

        // Establish WebSocket connection.
        const protocol = window.location.protocol === 'https:' ? 'wss' : 'ws';
        const socket = new WebSocket(protocol + '://' + window.location.host + "/ws/video/");
        // Expect binary blobs from the server.
        socket.binaryType = "blob";

        socket.onopen = () => {
            // Send initialization data.
            const initData = { subject_id: subjectData, session_year: sessionYearData };
            socket.send(JSON.stringify(initData));
            console.log("WebSocket connection established and initialization data sent.");
        };

        socket.onmessage = (e) => {
            // Handle messages from the server.
            if (typeof e.data === 'string') {
                try {
                    const data = JSON.parse(e.data);
                    if (data.frame) {
                        // Fallback: if frame is sent as a base64-encoded string.
                        frameQueue.push({ frame: data.frame, processed: data.processed });
                        if (!isDisplaying) displayNextFrame();
                    }
                    if (data.recognized_face_ids) {
                        // Print recognized face IDs to the console
                        console.log("Recognized Face IDs:", data.recognized_face_ids);
                    }
                } catch (err) {
                    console.error("Error parsing server text message:", err);
                }
            } else {
                // When receiving binary data (a Blob containing JPEG image).
                const url = URL.createObjectURL(e.data);
                frameQueue.push({ frame: url, processed: true });
                if (!isDisplaying) displayNextFrame();
            }
        };

        // Helper: Draw an image with a cover effect (mimicking object-fit: cover)
        function drawImageCover(ctx, img, canvasWidth, canvasHeight) {
            // Use natural dimensions of the image
            const imgWidth = img.naturalWidth;
            const imgHeight = img.naturalHeight;
            const canvasRatio = canvasWidth / canvasHeight;
            const imgRatio = imgWidth / imgHeight;
            let renderableWidth, renderableHeight, xStart, yStart;

            if (imgRatio > canvasRatio) {
                // Image is wider than canvas – scale height to fit, crop sides.
                renderableHeight = canvasHeight;
                renderableWidth = imgWidth * (canvasHeight / imgHeight);
                xStart = (canvasWidth - renderableWidth) / 2;
                yStart = 0;
            } else {
                // Image is taller than canvas – scale width to fit, crop top/bottom.
                renderableWidth = canvasWidth;
                renderableHeight = imgHeight * (canvasWidth / imgWidth);
                xStart = 0;
                yStart = (canvasHeight - renderableHeight) / 2;
            }
            ctx.drawImage(img, xStart, yStart, renderableWidth, renderableHeight);
        }

        // Display frames from the queue.
        function displayNextFrame() {
            if (frameQueue.length === 0) {
                isDisplaying = false;
                return;
            }
            isDisplaying = true;
            const frameObj = frameQueue.shift();
            const img = new Image();
            img.onload = () => {
                // Clear using the CSS dimensions (since we scaled the context)
                outputContext.clearRect(0, 0, window.innerWidth, window.innerHeight);
                // Draw the image with our cover effect using CSS dimensions.
                drawImageCover(outputContext, img, window.innerWidth, window.innerHeight);
                URL.revokeObjectURL(img.src);  // Clean up the object URL.
                // Display next frame after a short delay.
                setTimeout(displayNextFrame, 200);
            };
            img.src = frameObj.frame;
        }

        // Adjust canvas dimensions for high-DPI devices.
        function resizeCanvas() {
            const dpr = window.devicePixelRatio || 1;
            const displayWidth = window.innerWidth;
            const displayHeight = window.innerHeight;
            outputCanvas.width = displayWidth * dpr;
            outputCanvas.height = displayHeight * dpr;
            outputCanvas.style.width = displayWidth + 'px';
            outputCanvas.style.height = displayHeight + 'px';
            // Reset any existing transforms and scale the context.
            outputContext.setTransform(1, 0, 0, 1, 0, 0);
            outputContext.scale(dpr, dpr);
        }

        // Capture loop: periodically send frames to the server.
        let lastCaptureTime = 0;
        let captureIntervalMS = 200;  // Capture every 100ms (adjust as needed)

        function captureLoop(timestamp) {
            if (!lastCaptureTime) lastCaptureTime = timestamp;
            const elapsed = timestamp - lastCaptureTime;
            if (elapsed >= captureIntervalMS && video.readyState === video.HAVE_ENOUGH_DATA) {
                // Capture at a lower resolution for faster processing.
                const targetWidth = video.videoWidth;
                const targetHeight = video.videoHeight;
                captureCanvas.width = targetWidth;
                captureCanvas.height = targetHeight;
                captureContext.drawImage(video, 0, 0, targetWidth, targetHeight);
                // Convert the captured frame to a JPEG blob.
                captureCanvas.toBlob((blob) => {
                    if (socket.readyState === WebSocket.OPEN && blob) {
                        socket.send(blob);
                    }
                }, 'image/jpeg', 0.7);
                lastCaptureTime = timestamp;
            }
            if (capturing) requestAnimationFrame(captureLoop);
        }

        // Start or restart the camera stream.
        function startCamera() {
            if (stream) {
                stream.getTracks().forEach(track => track.stop());
            }
            capturing = false;
            const constraints = { video: { facingMode: currentFacingMode }, audio: false };
            navigator.mediaDevices.getUserMedia(constraints)
                .then(mediaStream => {
                    stream = mediaStream;
                    video.srcObject = stream;
                    video.play();
                    video.onloadedmetadata = () => {
                        // Resize the canvas to fill the viewport properly.
                        resizeCanvas();
                        // Start the capture loop.
                        capturing = true;
                        requestAnimationFrame(captureLoop);
                    };
                })
                .catch(err => console.error("Error accessing camera:", err));
        }

        // Adjust canvas on window resize (e.g., when mobile rotates)
        window.addEventListener('resize', () => {
            resizeCanvas();
        });

        // Start the camera when the page loads.
        startCamera();

        // Close camera on button click.
        closeBtn.addEventListener('click', () => {
            if (stream) {
                stream.getTracks().forEach(track => track.stop());
            }
            capturing = false;
            socket.close();
            window.location.href = '/staff_update_attendance';
        });

        // Toggle between front and back cameras.
        changeCameraBtn.addEventListener('click', () => {
            currentFacingMode = currentFacingMode === 'user' ? 'environment' : 'user';
            startCamera();
        });

        // Increase frame sending speed.
        increaseSpeedBtn.addEventListener('click', () => {
            captureIntervalMS = Math.max(100, captureIntervalMS - 100); // Decrease interval, min 10ms
            console.log("Increased frame sending speed. New interval:", captureIntervalMS, "ms");
        });

        // Decrease frame sending speed.
        decreaseSpeedBtn.addEventListener('click', () => {
            captureIntervalMS += 100; // Increase interval
            console.log("Decreased frame sending speed. New interval:", captureIntervalMS, "ms");
        });
    </script>
</body>

</html>